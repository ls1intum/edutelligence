# ----------------------------------------------------------------------------------------------------------------------
# Nebula base service
# ----------------------------------------------------------------------------------------------------------------------

services:
  transcriber:
    build:
      context: ../..
      dockerfile: ./nebula/docker/transcriber/Dockerfile
    container_name: transcriber-service
    expose:
      - "3870"
    environment:
      - LLM_CONFIG_PATH=/app/llm_config.nebula.yml
    restart: unless-stopped
    networks:
      - nebula

  faq:
    build:
      context: ../..
      dockerfile: ./nebula/docker/faq/Dockerfile
    container_name: faq-service
    expose:
      - "3871"
    environment:
      - LLM_CONFIG_PATH=/app/llm_config.nebula.yml
    restart: unless-stopped
    networks:
      - nebula

  nginx:
    image: huynhquangtoan/openresty-lua-resty-http:latest
    container_name: nginx-proxy
    ports:
      - "80:80"
      - "443:443"
    depends_on:
      - transcriber
      - faq
    restart: unless-stopped
    networks:
      - nebula

networks:
  nebula:
    driver: "bridge"
    name: nebula
