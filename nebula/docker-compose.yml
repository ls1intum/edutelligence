version: "3.9"

services:
  transcriber:
    build:
      context: .
      dockerfile: docker/transcriber/Dockerfile
    container_name: transcriber-service
    expose:
      - "5000"
    environment:
      - LLM_CONFIG_PATH=/app/llm_config.nebula.yml
    volumes:
      - ./llm_config.nebula.yml:/app/llm_config.nebula.yml:ro
      - ./temp:/app/temp
    restart: unless-stopped

  faq:
    build:
      context: .
      dockerfile: docker/faq/Dockerfile
    container_name: faq-service
    expose:
      - "5001"
    environment:
      - LLM_CONFIG_PATH=/app/llm_config.nebula.yml
    volumes:
      - ./llm_config.nebula.yml:/app/llm_config.nebula.yml:ro
    restart: unless-stopped

  envoy:
    image: envoyproxy/envoy:v1.30-latest
    container_name: envoy
    volumes:
      - ./envoy.yaml:/etc/envoy/envoy.yaml:ro
    ports:
      - "8000:8000" # HTTP for FastAPI
      - "9901:9901" # Admin interface
    depends_on:
      - transcriber
      - faq
    environment:
      - NEBULA_SECRET_TOKEN=${NEBULA_SECRET_TOKEN}
