# Nebula_Transcriber

Nebula_Transcriber is a lightweight transcription service for educational videos.  
It uses **Whisper** locally for audio transcription and **GPT-4o Vision** to detect visible slide numbers from video frames.

---

## ✨ Features

- 🎥 Process `.m3u8` lecture video URLs (e.g., from TUM-Live)
- 🧠 Transcribe audio using local Whisper models
- 👁️ Detect slide numbers via GPT-4o Vision (Azure)
- ⚡ Stateless and fast — no database or external storage
- 🚀 Exposes a clean **FastAPI** interface

---

## 🧪 Local Development Setup

```bash
git clone https://github.com/ls1intum/edutelligence.git
cd edutelligence
git checkout feature/transcript
cd nebula/src/nebula/transcript
```

```bash
python -m venv .venv
.venv\Scripts\activate      # on Windows
source .venv/bin/activate  # on Unix/Mac

pip install -r requirements.txt
```
## Environment Variables Setup
Windows-
Under Nebula/src
$env:APPLICATION_YML_PATH = "../application_local.nebula.yml"
$env:LLM_CONFIG_PATH = "../llm_config.nebula.yml"

Unix/macOS -
export APPLICATION_YML_PATH=../application_local.nebula.yml
export LLM_CONFIG_PATH=../llm_config.nebula.yml


Create `llm_config.nebula.yml`:
Copy llm_config.example.yml and add your api key

```yaml
- id: azure-gpt-4o
  type: azure_chat
  api_key: <your-gpt-api-key>
  api_version: 2024-02-15-preview
  azure_deployment: gpt-4o
  endpoint: https://<your-endpoint>.openai.azure.com/

- id: azure-whisper
  type: azure_whisper
  api_key: <your-whisper-api-key>
  api_version: 2024-06-01
  azure_deployment: whisper
  endpoint: https://<your-endpoint>.openai.azure.com/

```
Create `application_local.nebula.yml`:
Copy application_local.example.nebula.yml

Run the FastAPI app:

```bash
uvicorn nebula.transcript.app:app --reload --port 5000
```

---

## 🐳 Docker Setup

```bash
cd src/transcript/docker
docker compose up --build
```
Make sure the following files are present or mounted in the container:

`llm_config.nebula.yml`
`application_local.nebula.yml`
---

## 🚀 API Usage

**POST** `/api/lecture/{lectureId}/lecture-unit/{lectureUnitId}/nebula-transcriber`

```json
{
  "videoUrl": "https://your.video.url/playlist.m3u8",
  "lectureId": 1,
  "lectureUnitId": 2
}
```

---

## 🎓 Getting a TUM-Live `.m3u8` Link

1. Open [https://live.rbg.tum.de](https://live.rbg.tum.de/w/WiSe24ItP/55921 only 12 min)
2. Open DevTools → Network tab → Filter by `.m3u8`
3. Copy full link (including `jwt`)
4. Use in `videoUrl`

---

## 🧹 Temporary Files

- Stored in `./temp` by default
- Automatically removed after transcription
- Configurable via `.env`

---

## 📁 Project Structure

```
nebula/
├── src/
│   └── transcript/
│       ├── app.py
│       ├── slide_utils.py
│       ├── whisper_utils.py
│       ├── llm_utils.py
│       ├── config.py
│       └── docker/
│           └── docker-compose.yml
├── application_local.nebula.yml
├── llm_config.nebula.yml
└── temp/
```

---

## 🛠 Troubleshooting

- 404 from GPT Vision: Check Azure deployment name and API version
- Whisper FP16 warning: Ignored if using CPU
- FFmpeg error: Ensure it's installed and on PATH
- `proxies` error: Use OpenAI SDK ≤ 1.55.3 or strip extra config keys