{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Analysis Data Export\n",
    "Load the evaluation results and the participant information. Add the LLM as a participant (optional) and merge all data into a single dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.json_service import load_evaluation_progress, load_common_evaluation_config\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "evaluation_config_path = \"data/4_expert_evaluation/output_depseudonymized/common_evaluation_config.json\"\n",
    "evaluation_progress_path = \"data/4_expert_evaluation/output_depseudonymized/\"\n",
    "\n",
    "# Set this if you want to include the llm's evaluation.\n",
    "# Per default, the 5_llm_as_a_judge notebook stores the evaluation progress in \"data/5_llm_evaluation/evaluation_progress_llm-as-a-judge.json\"\n",
    "llm_evaluation_progress_path = None \n",
    "\n",
    "participant_info_path = \"data/6_analysis/participant_info.csv\"\n",
    "\n",
    "analysis_output_path = \"data/6_analysis/\"\n",
    "\n",
    "# Load evaluation progress\n",
    "df = load_evaluation_progress(evaluation_progress_path, llm_evaluation_progress_path)\n",
    "\n",
    "# Load evaluation config\n",
    "evaluation_config_df = load_common_evaluation_config(evaluation_config_path)\n",
    "df = df.merge(evaluation_config_df, on=[\"exercise_id\", \"submission_id\", \"feedback_type\"], how=\"left\")\n",
    "\n",
    "# Load participant info and add LLM as a participant\n",
    "participant_info_df = pd.read_csv(participant_info_path, delimiter=\";\")\n",
    "if llm_evaluation_progress_path:\n",
    "    participant_info_df = pd.concat([participant_info_df, pd.DataFrame([{\n",
    "        'expert_id': 'llm',\n",
    "        'evaluation_name': 'LLM as a judge',\n",
    "        'link': '',\n",
    "        'name': 'LLM',\n",
    "        'study_program': '',\n",
    "        'semester': pd.NA,\n",
    "        'eist_participation': pd.NA,\n",
    "        'pse_participation': pd.NA,\n",
    "        'tutoring_experience': pd.NA,\n",
    "        'group': 'LLM',\n",
    "    }])])\n",
    "df = df.merge(participant_info_df, on=[\"expert_id\"], how=\"left\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "### Export Data\n",
    "Select the relevant columns and export the data to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['expert_id', 'study_program', 'semester', 'eist_participation', 'pse_participation', 'tutoring_experience', 'group', 'exercise_id', 'submission_id', 'feedback_type', 'metric', 'score', 'exercise', 'submission', 'feedback']]\n",
    "\n",
    "os.makedirs(analysis_output_path, exist_ok=True)\n",
    "df.to_csv(os.path.join(analysis_output_path, \"evaluation_data.csv\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
