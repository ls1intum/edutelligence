{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "## Get the data from the database\n",
    "Sample the exercise IDs manually from the available exercises and adapt the `EXERCISE_IDS` variable accordingly.\n",
    "The `fetch_data_from_db` function fetches the data from the database for the specified exercise IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from service.db_service import fetch_data_from_db\n",
    "from langid import classify\n",
    "\n",
    "EXERCISE_IDS = [4066, 642, 544, 506]\n",
    "data = fetch_data_from_db(EXERCISE_IDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "The data preprocessing steps include:\n",
    "- Dropping rows with missing or invalid data.\n",
    "- Filtering out non-English submissions.\n",
    "\n",
    "You can adapt the data preprocessing steps based on the requirements of your evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Drop Rows with Missing or Invalid Data\n",
    "Drops the rows with missing data in the `submission_text` and `result_score` columns. Also, filters out submissions with no text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"submission_text\", \"result_score\"])\n",
    "data = data[data[\"submission_text\"].str.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "### Filter Out Non-English Submissions\n",
    "Filters out non-English submissions using the `langid` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_texts = data[\"submission_text\"].unique()\n",
    "classification_results = {text: classify(text)[0] == \"en\" for text in unique_texts}\n",
    "\n",
    "data[\"is_english\"] = data[\"submission_text\"].map(classification_results)\n",
    "data = data[data[\"is_english\"]]\n",
    "\n",
    "data = data.drop(columns=[\"is_english\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## Save the Sampled Exercises in a CSV File\n",
    "Saves the sampled exercises to a CSV file for the next steps in the evaluation process.\n",
    "You can also retrieve the sampled exercises from an existing CSV file using the `read_csv` command."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"data/1_exercises/exercises.csv\", index=False)\n",
    "# data = pd.read_csv(\"data/1_exercises/exercises.csv\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "evaluation-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
