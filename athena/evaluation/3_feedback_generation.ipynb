{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "30b71499cacdb3f3",
   "metadata": {},
   "source": [
    "## Feedback Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b8a6fdcab42f1d",
   "metadata": {},
   "source": [
    "### Generate Feedback Suggestions\n",
    "Upload the json files from `data/2_exercise_jsons` to the playground. In evaluation mode, generate feedback for each exercise and export the results. Make sure that the configuration names for feedback generation do not contain underscores '_'. Also make sure that the configuration names are unique for different feedback types but the same across different exercises.\n",
    "\n",
    "The downloaded json files should have the following naming scheme:\n",
    "`text_results_<Configuration name (e.g.: LLM)>_<...>`\n",
    "\n",
    "**Do not change the names of the downloaded files!**\n",
    "\n",
    "Save these files in the `data/3_feedback_suggestions` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f634beb67e8eb5d7",
   "metadata": {},
   "source": [
    "### Read Feedback Suggestions\n",
    "Once you have saved the feedback suggestion files in the `data/3_feedback_suggestions` directory, run the following cell to read the feedback suggestions from the files and to add them to the sampled submissions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be7c769",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T15:56:20.802661Z",
     "start_time": "2025-03-24T15:56:20.466838Z"
    }
   },
   "outputs": [],
   "source": [
    "from athena.evaluation.service.json_service import read_result_files_to_dataframe, add_feedback_suggestions_to_data, fill_missing_feedback_with_tutor_feedback\n",
    "import pandas as pd\n",
    "\n",
    "sampled_submissions = pd.read_csv(\"data/2_sampled_submissions.csv\")\n",
    "feedback_suggestions = read_result_files_to_dataframe(\"data/3_feedback_suggestions\")\n",
    "\n",
    "sampled_submissions_with_feedback = add_feedback_suggestions_to_data(sampled_submissions, feedback_suggestions)\n",
    "sampled_submissions_with_feedback = fill_missing_feedback_with_tutor_feedback(sampled_submissions_with_feedback)\n",
    "\n",
    "sampled_submissions_with_feedback = sampled_submissions_with_feedback.assign(feedback_text=None)\n",
    "\n",
    "sampled_submissions_with_feedback.to_csv(\"../data/3_sampled_submissions_with_feedback.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb2a48ff78d65d0",
   "metadata": {},
   "source": [
    "### Save the Feedback Suggestions\n",
    "Save the feedback suggestions to a JSON file for the next steps in the evaluation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2392b2c8659698e9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T15:56:21.040975Z",
     "start_time": "2025-03-24T15:56:20.811535Z"
    }
   },
   "outputs": [],
   "source": [
    "from athena.evaluation.service.json_service import group_exercise_data, exercises_to_json\n",
    "\n",
    "exercises = group_exercise_data(sampled_submissions_with_feedback)\n",
    "exercises_to_json(exercises, \"data/3_submissions_with_categorized_feedback_jsons\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b3ddaaab29c7b1",
   "metadata": {},
   "source": [
    "## Example of Analysing the Sampled Submissions with Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd83802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-24T15:56:21.160930Z",
     "start_time": "2025-03-24T15:56:21.140135Z"
    }
   },
   "outputs": [],
   "source": [
    "grouped_data = (\n",
    "    sampled_submissions_with_feedback\n",
    "    .groupby([\"exercise_id\", \"result_score\"])\n",
    "    .agg(\n",
    "        submission_count=(\"submission_id\", \"nunique\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "total_submissions_per_exercise = (\n",
    "    sampled_submissions_with_feedback\n",
    "    .groupby(\"exercise_id\")[\"submission_id\"]\n",
    "    .nunique()\n",
    "    .reset_index()\n",
    "    .rename(columns={\"submission_id\": \"total_submission_count\"})\n",
    ")\n",
    "grouped_data = grouped_data.merge(total_submissions_per_exercise, on=\"exercise_id\", how=\"left\")\n",
    "\n",
    "feedback_types = sampled_submissions_with_feedback[\"feedback_type\"].unique()\n",
    "for feedback_type in feedback_types:\n",
    "    feedback_data = sampled_submissions_with_feedback[sampled_submissions_with_feedback[\"feedback_type\"] == feedback_type]\n",
    "\n",
    "    feedback_count = (\n",
    "        feedback_data\n",
    "        .groupby([\"exercise_id\", \"result_score\"])[\"feedback_id\"]\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"feedback_id\": f\"feedback_count_{feedback_type}\"})\n",
    "    )\n",
    "    grouped_data = grouped_data.merge(feedback_count, on=[\"exercise_id\", \"result_score\"], how=\"left\")\n",
    "    grouped_data[f\"feedback_count_{feedback_type}\"] = grouped_data[f\"feedback_count_{feedback_type}\"].fillna(0).astype(int)\n",
    "    \n",
    "    total_feedback_count = (\n",
    "        feedback_data\n",
    "        .groupby(\"exercise_id\")[\"feedback_id\"]\n",
    "        .nunique()\n",
    "        .reset_index()\n",
    "        .rename(columns={\"feedback_id\": f\"total_feedback_count_{feedback_type}\"})\n",
    "    )\n",
    "    grouped_data = grouped_data.merge(total_feedback_count, on=\"exercise_id\", how=\"left\")\n",
    "    grouped_data[f\"total_feedback_count_{feedback_type}\"] = grouped_data[f\"total_feedback_count_{feedback_type}\"].fillna(0).astype(int)\n",
    "    \n",
    "    grouped_data[f\"average_feedback_count_{feedback_type}\"] = (\n",
    "        grouped_data[f\"feedback_count_{feedback_type}\"] / grouped_data[\"submission_count\"]\n",
    "    ).fillna(0)\n",
    "\n",
    "\n",
    "grouped_data.to_csv(\"../data/2_feedback_counts.csv\", index=False)\n",
    "grouped_data"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
